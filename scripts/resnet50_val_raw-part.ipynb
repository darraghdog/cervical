{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "ROWS, COLS = 224, 224\n",
    "CHECKPOINT_DIR = 'log/checkpoint02/'\n",
    "BATCHSIZE = 32\n",
    "CERV_CLASSES = ['Type_1', 'Type_2', 'Type_3']\n",
    "nb_perClass = int(BATCHSIZE / len(CERV_CLASSES))\n",
    "TRAIN_DIR = '../data/train'\n",
    "TEST_DIR = '../data/test'\n",
    "DATA_DIR = '../data'\n",
    "num_class = len(CERV_CLASSES)\n",
    "full = False\n",
    "bags = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "y_ls = []\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(TRAIN_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(TRAIN_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(DATA_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(DATA_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "train_all  = pd.DataFrame({'class': y_ls, 'img': img_ls, })[['img', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "for img in os.listdir(TEST_DIR):\n",
    "    if img != '.DS_Store':\n",
    "        img_ls.append(os.path.join(TEST_DIR, img))\n",
    "test_df  = pd.DataFrame({'img': img_ls}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>../data/Type_3/5391.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>../data/Type_3/4116.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>../data/Type_3/568.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          img   class\n",
       "8209  ../data/Type_3/5391.jpg  Type_3\n",
       "8210  ../data/Type_3/4116.jpg  Type_3\n",
       "8211   ../data/Type_3/568.jpg  Type_3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            #x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "            i += 1\n",
    "        #return (batch_x, batch_y)\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "valid_set[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8212, 2)\n",
      "(1642, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[train_all['img'].str.replace('../data/', '').isin(valid_set)]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[~train_all['img'].isin(valid_set)]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_per_epoch = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(df, datagen, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            # typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            # x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%100 == 0: print(batch_index)\n",
    "        # return (batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "model_checkpoint = ModelCheckpoint(filepath=CHECKPOINT_DIR+'weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "# learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "# tensorboard = TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=False, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation... \n",
      "Fine tune part 1\n",
      "Epoch 1/2\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 1.0207 - acc: 0.4026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 1.01069, saving model to log/checkpoint02/weights.000-1.0107.hdf5\n",
      "5024/5000 [==============================] - 1062s - loss: 1.0188 - acc: 0.4047 - val_loss: 1.0107 - val_acc: 0.5024\n",
      "Epoch 2/2\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.8885 - acc: 0.5086Epoch 00001: val_loss improved from 1.01069 to 0.91860, saving model to log/checkpoint02/weights.001-0.9186.hdf5\n",
      "5024/5000 [==============================] - 1016s - loss: 0.8877 - acc: 0.5086 - val_loss: 0.9186 - val_acc: 0.5463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe8f8c3e90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Model creation... \"\n",
    "nb_epoch = 2\n",
    "model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Start Fine-tuning\n",
    "print \"Fine tune part 1\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 1A\n",
      "Epoch 1/4\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.7993 - acc: 0.5673Epoch 00000: val_loss improved from 0.91860 to 0.90205, saving model to log/checkpoint02/weights.000-0.9020.hdf5\n",
      "5024/5000 [==============================] - 1038s - loss: 0.7995 - acc: 0.5673 - val_loss: 0.9020 - val_acc: 0.5694\n",
      "Epoch 2/4\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.7590 - acc: 0.6076Epoch 00001: val_loss improved from 0.90205 to 0.78604, saving model to log/checkpoint02/weights.001-0.7860.hdf5\n",
      "5024/5000 [==============================] - 1005s - loss: 0.7590 - acc: 0.6079 - val_loss: 0.7860 - val_acc: 0.6358\n",
      "Epoch 3/4\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.7082 - acc: 0.6322Epoch 00002: val_loss improved from 0.78604 to 0.75112, saving model to log/checkpoint02/weights.002-0.7511.hdf5\n",
      "5024/5000 [==============================] - 1003s - loss: 0.7079 - acc: 0.6324 - val_loss: 0.7511 - val_acc: 0.6620\n",
      "Epoch 4/4\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.6521 - acc: 0.6679Epoch 00003: val_loss improved from 0.75112 to 0.67515, saving model to log/checkpoint02/weights.003-0.6751.hdf5\n",
      "5024/5000 [==============================] - 1000s - loss: 0.6513 - acc: 0.6682 - val_loss: 0.6751 - val_acc: 0.7065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe8f8c7f50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Fine-tuning\n",
    "nb_epoch = 4\n",
    "print \"Fine tune part 1A\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from keras.models import load_model, model_from_json\n",
    "#model = load_model('log/checkpoint01weights.003-0.7728.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 2\n",
      "Epoch 1/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.5984 - acc: 0.7037Epoch 00000: val_loss improved from 0.67515 to 0.63066, saving model to log/checkpoint02/weights.000-0.6307.hdf5\n",
      "5024/5000 [==============================] - 1017s - loss: 0.5980 - acc: 0.7042 - val_loss: 0.6307 - val_acc: 0.7345\n",
      "Epoch 2/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.5573 - acc: 0.7250Epoch 00001: val_loss improved from 0.63066 to 0.57775, saving model to log/checkpoint02/weights.001-0.5777.hdf5\n",
      "5024/5000 [==============================] - 990s - loss: 0.5568 - acc: 0.7251 - val_loss: 0.5777 - val_acc: 0.7619\n",
      "Epoch 3/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.5346 - acc: 0.7400Epoch 00002: val_loss improved from 0.57775 to 0.53976, saving model to log/checkpoint02/weights.002-0.5398.hdf5\n",
      "5024/5000 [==============================] - 990s - loss: 0.5337 - acc: 0.7406 - val_loss: 0.5398 - val_acc: 0.7917\n",
      "Epoch 4/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.4850 - acc: 0.7726Epoch 00003: val_loss improved from 0.53976 to 0.47518, saving model to log/checkpoint02/weights.003-0.4752.hdf5\n",
      "5024/5000 [==============================] - 991s - loss: 0.4854 - acc: 0.7729 - val_loss: 0.4752 - val_acc: 0.8252\n",
      "Epoch 5/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.4436 - acc: 0.7899Epoch 00004: val_loss improved from 0.47518 to 0.45449, saving model to log/checkpoint02/weights.004-0.4545.hdf5\n",
      "5024/5000 [==============================] - 998s - loss: 0.4431 - acc: 0.7898 - val_loss: 0.4545 - val_acc: 0.8423\n",
      "Epoch 6/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.4059 - acc: 0.8047Epoch 00005: val_loss improved from 0.45449 to 0.41127, saving model to log/checkpoint02/weights.005-0.4113.hdf5\n",
      "5024/5000 [==============================] - 992s - loss: 0.4052 - acc: 0.8055 - val_loss: 0.4113 - val_acc: 0.8575\n",
      "Epoch 7/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.3808 - acc: 0.8131Epoch 00006: val_loss improved from 0.41127 to 0.38317, saving model to log/checkpoint02/weights.006-0.3832.hdf5\n",
      "5024/5000 [==============================] - 987s - loss: 0.3805 - acc: 0.8133 - val_loss: 0.3832 - val_acc: 0.8819\n",
      "Epoch 8/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.3419 - acc: 0.8397Epoch 00007: val_loss improved from 0.38317 to 0.33319, saving model to log/checkpoint02/weights.007-0.3332.hdf5\n",
      "5024/5000 [==============================] - 985s - loss: 0.3414 - acc: 0.8402 - val_loss: 0.3332 - val_acc: 0.9074\n",
      "Epoch 9/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.3161 - acc: 0.8500Epoch 00008: val_loss improved from 0.33319 to 0.30541, saving model to log/checkpoint02/weights.008-0.3054.hdf5\n",
      "5024/5000 [==============================] - 982s - loss: 0.3159 - acc: 0.8501 - val_loss: 0.3054 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.2823 - acc: 0.8678Epoch 00009: val_loss improved from 0.30541 to 0.28555, saving model to log/checkpoint02/weights.009-0.2856.hdf5\n",
      "5024/5000 [==============================] - 990s - loss: 0.2821 - acc: 0.8680 - val_loss: 0.2856 - val_acc: 0.9208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbeca584850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers[38:]:\n",
    "    layer.trainable = True\n",
    "#model.optimizer.lr = 1e-5\n",
    "nb_epoch = 10\n",
    "print \"Fine tune part 2\"\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[model_checkpoint, early_stopping], # , \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.2662 - acc: 0.8720Epoch 00000: val_loss improved from 0.28555 to 0.25546, saving model to log/checkpoint02/weights.000-0.2555.hdf5\n",
      "5024/5000 [==============================] - 1008s - loss: 0.2658 - acc: 0.8720 - val_loss: 0.2555 - val_acc: 0.9294\n",
      "Epoch 2/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.2277 - acc: 0.8896Epoch 00001: val_loss improved from 0.25546 to 0.22854, saving model to log/checkpoint02/weights.001-0.2285.hdf5\n",
      "5024/5000 [==============================] - 984s - loss: 0.2279 - acc: 0.8897 - val_loss: 0.2285 - val_acc: 0.9452\n",
      "Epoch 3/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.2128 - acc: 0.8922Epoch 00002: val_loss improved from 0.22854 to 0.20463, saving model to log/checkpoint02/weights.002-0.2046.hdf5\n",
      "5024/5000 [==============================] - 985s - loss: 0.2124 - acc: 0.8923 - val_loss: 0.2046 - val_acc: 0.9513\n",
      "Epoch 4/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.1897 - acc: 0.8988Epoch 00003: val_loss improved from 0.20463 to 0.18399, saving model to log/checkpoint02/weights.003-0.1840.hdf5\n",
      "5024/5000 [==============================] - 988s - loss: 0.1895 - acc: 0.8991 - val_loss: 0.1840 - val_acc: 0.9629\n",
      "Epoch 5/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.1730 - acc: 0.9083Epoch 00004: val_loss improved from 0.18399 to 0.15952, saving model to log/checkpoint02/weights.004-0.1595.hdf5\n",
      "5024/5000 [==============================] - 989s - loss: 0.1731 - acc: 0.9082 - val_loss: 0.1595 - val_acc: 0.9708\n",
      "Epoch 6/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.1562 - acc: 0.9099Epoch 00005: val_loss did not improve\n",
      "5024/5000 [==============================] - 982s - loss: 0.1566 - acc: 0.9094 - val_loss: 0.1703 - val_acc: 0.9592\n",
      "Epoch 7/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.1438 - acc: 0.9115Epoch 00006: val_loss improved from 0.15952 to 0.12049, saving model to log/checkpoint02/weights.006-0.1205.hdf5\n",
      "5024/5000 [==============================] - 993s - loss: 0.1436 - acc: 0.9116 - val_loss: 0.1205 - val_acc: 0.9817\n",
      "Epoch 8/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.1315 - acc: 0.9165Epoch 00007: val_loss did not improve\n",
      "5024/5000 [==============================] - 993s - loss: 0.1316 - acc: 0.9164 - val_loss: 0.1334 - val_acc: 0.9769\n",
      "Epoch 9/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.1115 - acc: 0.9247Epoch 00008: val_loss improved from 0.12049 to 0.09933, saving model to log/checkpoint02/weights.008-0.0993.hdf5\n",
      "5024/5000 [==============================] - 985s - loss: 0.1114 - acc: 0.9248 - val_loss: 0.0993 - val_acc: 0.9823\n",
      "Epoch 10/10\n",
      "4992/5000 [============================>.] - ETA: 1s - loss: 0.1063 - acc: 0.9229Epoch 00009: val_loss improved from 0.09933 to 0.08589, saving model to log/checkpoint02/weights.009-0.0859.hdf5\n",
      "5024/5000 [==============================] - 985s - loss: 0.1062 - acc: 0.9230 - val_loss: 0.0859 - val_acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbecad1c910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "# val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "# # weights.009-0.2856.hdf5\n",
    "# index = val_losses.index(min(val_losses))\n",
    "# print('Loading model from checkpoints file ' + files[index])\n",
    "# model = load_model(files[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 'log/checkpoint02/weights.000-0.2555.hdf5'\n",
      "Update 'log/checkpoint02/weights.000-0.6307.hdf5'\n",
      "Update 'log/checkpoint02/weights.000-0.9020.hdf5'\n",
      "Update 'log/checkpoint02/weights.000-1.0107.hdf5'\n",
      "Update 'log/checkpoint02/weights.001-0.2285.hdf5'\n",
      "Update 'log/checkpoint02/weights.001-0.5777.hdf5'\n",
      "Update 'log/checkpoint02/weights.001-0.7860.hdf5'\n",
      "Update 'log/checkpoint02/weights.001-0.9186.hdf5'\n",
      "Update 'log/checkpoint02/weights.002-0.2046.hdf5'\n",
      "Update 'log/checkpoint02/weights.002-0.5398.hdf5'\n",
      "Update 'log/checkpoint02/weights.002-0.7511.hdf5'\n",
      "Update 'log/checkpoint02/weights.003-0.1840.hdf5'\n",
      "Update 'log/checkpoint02/weights.003-0.4752.hdf5'\n",
      "Update 'log/checkpoint02/weights.003-0.6751.hdf5'\n",
      "Update 'log/checkpoint02/weights.004-0.1595.hdf5'\n",
      "Update 'log/checkpoint02/weights.004-0.4545.hdf5'\n",
      "Update 'log/checkpoint02/weights.005-0.4113.hdf5'\n",
      "Update 'log/checkpoint02/weights.006-0.1205.hdf5'\n",
      "Update 'log/checkpoint02/weights.006-0.3832.hdf5'\n",
      "Update 'log/checkpoint02/weights.007-0.3332.hdf5'\n",
      "Update 'log/checkpoint02/weights.008-0.0993.hdf5'\n",
      "Update 'log/checkpoint02/weights.008-0.3054.hdf5'\n",
      "Update 'log/checkpoint02/weights.009-0.0859.hdf5'\n",
      "Update 'log/checkpoint02/weights.009-0.2856.hdf5'\n"
     ]
    }
   ],
   "source": [
    "# Hack to solve issue on model loading : https://github.com/fchollet/keras/issues/4044\n",
    "import glob\n",
    "import h5py\n",
    "model_files = sorted(glob.glob('log/checkpoint02/*.hdf5'))\n",
    "for model_file in model_files:\n",
    "    print(\"Update '{}'\".format(model_file))\n",
    "    with h5py.File(model_file, 'a') as f:\n",
    "        if 'optimizer_weights' in f.keys():\n",
    "            del f['optimizer_weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a prediction from a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('log/checkpoint02/weights.009-0.2856.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400.jpg</td>\n",
       "      <td>0.202256</td>\n",
       "      <td>0.129008</td>\n",
       "      <td>0.668735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>430.jpg</td>\n",
       "      <td>0.088869</td>\n",
       "      <td>0.504176</td>\n",
       "      <td>0.406955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303.jpg</td>\n",
       "      <td>0.869445</td>\n",
       "      <td>0.124915</td>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name    Type_1    Type_2    Type_3\n",
       "0    400.jpg  0.202256  0.129008  0.668735\n",
       "1    430.jpg  0.088869  0.504176  0.406955\n",
       "2    303.jpg  0.869445  0.124915  0.005641"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_resnet_raw_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_resnet_raw_' + timestr + '.csv' #'.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... this got LB 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='../sub/sub_dara_part_resnet_raw_20170510.csv' target='_blank'>../sub/sub_dara_part_resnet_raw_20170510.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/cervical/sub/sub_dara_part_resnet_raw_20170510.csv"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag the predictions from a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "# there is apparently overfitting on the later epochs so exclude the epochs where we unfroze the top layers\n",
    "files = [f for f in files if float(f.split('-')[-1][:-5])>0.26]\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "min_id = np.array(val_losses).argsort()[:bags].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints file log/checkpoint02/weights.009-0.2856.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint02/weights.008-0.3054.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint02/weights.007-0.3332.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint02/weights.006-0.3832.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint02/weights.005-0.4113.hdf5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Loop the lowest val losses and get a prediction for each\n",
    "test_preds_ls = []\n",
    "for index in min_id:\n",
    "    print('Loading model from checkpoints file ' + files[index])\n",
    "    test_model = load_model(files[index])\n",
    "    test_model_name = files[index].split('/')[-2][-1:]+'_'+files[index].split('/')[-1]\n",
    "    test_preds_ls.append(test_model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) \n",
    "    del test_model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = sum(test_preds_ls)/len(test_preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400.jpg</td>\n",
       "      <td>0.254422</td>\n",
       "      <td>0.156392</td>\n",
       "      <td>0.589186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>430.jpg</td>\n",
       "      <td>0.087055</td>\n",
       "      <td>0.594300</td>\n",
       "      <td>0.318645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303.jpg</td>\n",
       "      <td>0.845521</td>\n",
       "      <td>0.146083</td>\n",
       "      <td>0.008396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name    Type_1    Type_2    Type_3\n",
       "0    400.jpg  0.254422  0.156392  0.589186\n",
       "1    430.jpg  0.087055  0.594300  0.318645\n",
       "2    303.jpg  0.845521  0.146083  0.008396"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .. @LB : 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='../sub/sub_dara_part_resnet_raw_5xbag_20170510.csv' target='_blank'>../sub/sub_dara_part_resnet_raw_5xbag_20170510.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/cervical/sub/sub_dara_part_resnet_raw_5xbag_20170510.csv"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "    \n",
    "test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
