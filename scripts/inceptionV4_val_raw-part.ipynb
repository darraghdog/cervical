{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model\n",
    "from cnnmodels import conv2d_bn, block_inception_a, block_reduction_a, block_inception_b, block_reduction_b\n",
    "from cnnmodels import block_inception_c, inception_v4_base, inception_v4_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 299, 299 # Resolution of inputs\n",
    "channel = 3\n",
    "ROWS, COLS = 299, 299\n",
    "CHECKPOINT_DIR = 'log/checkpoint07/'\n",
    "BATCHSIZE = 32\n",
    "CERV_CLASSES = ['Type_1', 'Type_2', 'Type_3']\n",
    "nb_perClass = int(BATCHSIZE / len(CERV_CLASSES))\n",
    "TRAIN_DIR = '../data/original/train'\n",
    "TEST_DIR = '../data/original/test'\n",
    "DATA_DIR = '../data/original'\n",
    "num_class = len(CERV_CLASSES)\n",
    "full = False\n",
    "bags = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "y_ls = []\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(TRAIN_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(TRAIN_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(DATA_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(DATA_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "train_all  = pd.DataFrame({'class': y_ls, 'img': img_ls, })[['img', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "for img in os.listdir(TEST_DIR):\n",
    "    if img != '.DS_Store':\n",
    "        img_ls.append(os.path.join(TEST_DIR, img))\n",
    "test_df  = pd.DataFrame({'img': img_ls}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>../data/original/Type_3/5391.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>../data/original/Type_3/4116.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>../data/original/Type_3/568.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   img   class\n",
       "8206  ../data/original/Type_3/5391.jpg  Type_3\n",
       "8207  ../data/original/Type_3/4116.jpg  Type_3\n",
       "8208   ../data/original/Type_3/568.jpg  Type_3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            #x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "            i += 1\n",
    "        #return (batch_x, batch_y)\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "valid_set[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8209, 2)\n",
      "(1641, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[~train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#samples_per_epoch = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(df, datagen, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            # typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            # x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%100 == 0: print(batch_index)\n",
    "        # return (batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "model_checkpoint = ModelCheckpoint(filepath=CHECKPOINT_DIR+'weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "# learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "# tensorboard = TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=False, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation... \n",
      "Fine tune part 1\n",
      "Epoch 1/5\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.7761 - acc: 0.5772Epoch 00000: val_loss improved from inf to 0.55488, saving model to log/checkpoint07/weights.000-0.5549.hdf5\n",
      "13888/13888 [==============================] - 1947s - loss: 0.7759 - acc: 0.5772 - val_loss: 0.5549 - val_acc: 0.7709\n",
      "Epoch 2/5\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.3373 - acc: 0.8083Epoch 00001: val_loss improved from 0.55488 to 0.27014, saving model to log/checkpoint07/weights.001-0.2701.hdf5\n",
      "13888/13888 [==============================] - 1957s - loss: 0.3368 - acc: 0.8085 - val_loss: 0.2701 - val_acc: 0.9037\n",
      "Epoch 3/5\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.1548 - acc: 0.8887Epoch 00002: val_loss improved from 0.27014 to 0.13826, saving model to log/checkpoint07/weights.002-0.1383.hdf5\n",
      "13888/13888 [==============================] - 1938s - loss: 0.1547 - acc: 0.8887 - val_loss: 0.1383 - val_acc: 0.9512\n",
      "Epoch 4/5\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.0848 - acc: 0.9102Epoch 00003: val_loss improved from 0.13826 to 0.06202, saving model to log/checkpoint07/weights.003-0.0620.hdf5\n",
      "13888/13888 [==============================] - 1937s - loss: 0.0847 - acc: 0.9104 - val_loss: 0.0620 - val_acc: 0.9787\n",
      "Epoch 5/5\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.0400 - acc: 0.9287Epoch 00004: val_loss improved from 0.06202 to 0.04833, saving model to log/checkpoint07/weights.004-0.0483.hdf5\n",
      "13888/13888 [==============================] - 1936s - loss: 0.0399 - acc: 0.9287 - val_loss: 0.0483 - val_acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9af0190f50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Model creation... \"\n",
    "nb_epoch = 5\n",
    "# (img_rows, img_cols, color_type=1, num_classeses=None, dropout_keep_prob=0.2)\n",
    "model = inception_v4_model(ROWS, COLS, channel, num_classes=num_class, dropout_keep_prob=0.2)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Start Fine-tuning\n",
    "print \"Fine tune part 1\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-20:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 1B\n",
      "Epoch 1/4\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.0321 - acc: 0.9324Epoch 00000: val_loss improved from 0.04833 to 0.02417, saving model to log/checkpoint07/weights.000-0.0242.hdf5\n",
      "13888/13888 [==============================] - 1938s - loss: 0.0320 - acc: 0.9324 - val_loss: 0.0242 - val_acc: 0.9933\n",
      "Epoch 2/4\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.0239 - acc: 0.9327Epoch 00001: val_loss did not improve\n",
      "13888/13888 [==============================] - 1937s - loss: 0.0239 - acc: 0.9327 - val_loss: 0.0364 - val_acc: 0.9872\n",
      "Epoch 3/4\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.0161 - acc: 0.9333Epoch 00002: val_loss did not improve\n",
      "13888/13888 [==============================] - 1938s - loss: 0.0161 - acc: 0.9333 - val_loss: 0.0449 - val_acc: 0.9829\n",
      "Epoch 4/4\n",
      "13856/13888 [============================>.] - ETA: 4s - loss: 0.0165 - acc: 0.9330Epoch 00003: val_loss improved from 0.02417 to 0.01945, saving model to log/checkpoint07/weights.003-0.0195.hdf5\n",
      "13888/13888 [==============================] - 1938s - loss: 0.0165 - acc: 0.9330 - val_loss: 0.0195 - val_acc: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b67dc48d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Fine-tuning\n",
    "nb_epoch = 4\n",
    "print \"Fine tune part 1B\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 'log/checkpoint07/weights.000-0.0242.hdf5'\n",
      "Update 'log/checkpoint07/weights.000-0.5549.hdf5'\n",
      "Update 'log/checkpoint07/weights.001-0.2701.hdf5'\n",
      "Update 'log/checkpoint07/weights.002-0.1383.hdf5'\n",
      "Update 'log/checkpoint07/weights.003-0.0195.hdf5'\n",
      "Update 'log/checkpoint07/weights.003-0.0620.hdf5'\n",
      "Update 'log/checkpoint07/weights.004-0.0483.hdf5'\n"
     ]
    }
   ],
   "source": [
    "# Hack to solve issue on model loading : https://github.com/fchollet/keras/issues/4044\n",
    "import glob\n",
    "import h5py\n",
    "model_files = sorted(glob.glob(CHECKPOINT_DIR + '*.hdf5'))\n",
    "for model_file in model_files:\n",
    "    print(\"Update '{}'\".format(model_file))\n",
    "    with h5py.File(model_file, 'a') as f:\n",
    "        if 'optimizer_weights' in f.keys():\n",
    "            del f['optimizer_weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag the predictions from a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "from IPython.lib.display import FileLink\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "# there is apparently overfitting on the later epochs so exclude the epochs where we unfroze the top layers\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "min_id = np.array(val_losses).argsort()[:bags].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  8.36955130e-01,   1.99344680e-02,   1.43110365e-01],\n",
       "        [  2.66181596e-05,   9.99951959e-01,   2.14751581e-05],\n",
       "        [  9.94375825e-01,   4.60151955e-03,   1.02260814e-03],\n",
       "        ..., \n",
       "        [  1.07146610e-04,   9.24942493e-01,   7.49503002e-02],\n",
       "        [  2.20124421e-05,   2.11369749e-02,   9.78840947e-01],\n",
       "        [  5.43637289e-05,   9.99937415e-01,   8.18345870e-06]], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints file log/checkpoint07/weights.003-0.0195.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint07/weights.000-0.0242.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint07/weights.004-0.0483.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint07/weights.003-0.0620.hdf5\n",
      "0\n",
      "Loading model from checkpoints file log/checkpoint07/weights.002-0.1383.hdf5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Loop the lowest val losses and get a prediction for each\n",
    "test_preds_ls = []\n",
    "model = inception_v4_model(ROWS, COLS, channel, num_classes=num_class, dropout_keep_prob=0.2)\n",
    "for index in min_id:\n",
    "    print('Loading model from checkpoints file ' + files[index])\n",
    "    model.load_weights(files[index])\n",
    "    test_model_name = files[index].split('/')[-2][-1:]+'_'+files[index].split('/')[-1]\n",
    "    test_preds_ls.append(model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = sum(test_preds_ls)/len(test_preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400.jpg</td>\n",
       "      <td>0.727681</td>\n",
       "      <td>0.062392</td>\n",
       "      <td>0.209927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>430.jpg</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.988899</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303.jpg</td>\n",
       "      <td>0.885383</td>\n",
       "      <td>0.060143</td>\n",
       "      <td>0.054474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name    Type_1    Type_2    Type_3\n",
       "0    400.jpg  0.727681  0.062392  0.209927\n",
       "1    430.jpg  0.010558  0.988899  0.000543\n",
       "2    303.jpg  0.885383  0.060143  0.054474"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='../sub/sub_dara_part_resnet_raw_5xbag_20170521.csv' target='_blank'>../sub/sub_dara_part_resnet_raw_5xbag_20170521.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/cervical/sub/sub_dara_part_resnet_raw_5xbag_20170521.csv"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "    \n",
    "test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
