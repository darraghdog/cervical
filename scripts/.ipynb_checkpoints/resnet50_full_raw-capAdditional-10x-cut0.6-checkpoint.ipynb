{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 85.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "ROWS, COLS = 224, 224\n",
    "CHECKPOINT_DIR = 'log/checkpoint09/'\n",
    "BATCHSIZE = 32\n",
    "CERV_CLASSES = ['Type_1', 'Type_2', 'Type_3']\n",
    "nb_perClass = int(BATCHSIZE / len(CERV_CLASSES))\n",
    "TRAIN_DIR = '../data/original/train'\n",
    "TEST_DIR = '../data/original/test'\n",
    "DATA_DIR = '../data/original'\n",
    "num_class = len(CERV_CLASSES)\n",
    "full = True\n",
    "bags = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            #x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "            i += 1\n",
    "        #return (batch_x, batch_y)\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(df, datagen, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            # typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            # x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%100 == 0: print(batch_index)\n",
    "        # return (batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480, 2)\n",
      "(6729, 2)\n"
     ]
    }
   ],
   "source": [
    "img_ls = []\n",
    "y_ls = []\n",
    "imgadd_ls = []\n",
    "yadd_ls = []\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(TRAIN_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(TRAIN_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(DATA_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            imgadd_ls.append(os.path.join(DATA_DIR, typ, img))\n",
    "            yadd_ls.append(typ)\n",
    "train_orig_all  = pd.DataFrame({'class': y_ls, 'img': img_ls, })[['img', 'class']]\n",
    "train_addl_all  = pd.DataFrame({'class': yadd_ls, 'img': imgadd_ls, })[['img', 'class']]\n",
    "print(train_orig_all.shape)\n",
    "print(train_addl_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = train_orig_all\n",
    "test_df =   train_addl_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "valid_set[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480, 2)\n",
      "(242, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[~train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "model_checkpoint = ModelCheckpoint(filepath=CHECKPOINT_DIR+'weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "# learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "# tensorboard = TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=False, write_images=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print \"Model creation... \"\n",
    "nb_epoch = 4\n",
    "model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Start Fine-tuning\n",
    "print \"Fine tune part 1\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for layer in model.layers[38:]:\n",
    "    layer.trainable = True\n",
    "#model.optimizer.lr = 1e-5\n",
    "nb_epoch = 2\n",
    "print \"Fine tune part 2\"\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[model_checkpoint, early_stopping], # , \n",
    "          )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_preds_ls = []\n",
    "for ii in range(2):\n",
    "    test_preds_ls.append(model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) \n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=1,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              #callbacks=[model_checkpoint, early_stopping], # , \n",
    "              )\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_preds_ls.append(model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_preds = sum(test_preds_ls)/len(test_preds_ls)\n",
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img']#.str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.to_csv('../feat/additional_pred.csv', index=False)#, compression='gzip')\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/original/Type_1/2399.jpg</td>\n",
       "      <td>0.564977</td>\n",
       "      <td>0.412536</td>\n",
       "      <td>0.022487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/original/Type_1/1704.jpg</td>\n",
       "      <td>0.762905</td>\n",
       "      <td>0.157422</td>\n",
       "      <td>0.079673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/original/Type_1/3237.jpg</td>\n",
       "      <td>0.825580</td>\n",
       "      <td>0.159832</td>\n",
       "      <td>0.014588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image_name    Type_1    Type_2    Type_3\n",
       "0  ../data/original/Type_1/2399.jpg  0.564977  0.412536  0.022487\n",
       "1  ../data/original/Type_1/1704.jpg  0.762905  0.157422  0.079673\n",
       "2  ../data/original/Type_1/3237.jpg  0.825580  0.159832  0.014588"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = pd.read_csv('../feat/additional_pred.csv')\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_additional = []\n",
    "bad_additional = []\n",
    "for c, row in test_sub.iterrows():\n",
    "    typ = int(row[0].split('/')[3][-1])\n",
    "    if row[typ] >= 0.6:\n",
    "        good_additional.append(row[0])\n",
    "    else:\n",
    "        bad_additional.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3852, 2877)\n"
     ]
    }
   ],
   "source": [
    "print(len(good_additional), len(bad_additional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have the good and bad additionals, lets do a full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = pd.concat([train_orig_all, train_addl_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = train_all[~train_all['img'].isin(bad_additional)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "for img in os.listdir(TEST_DIR):\n",
    "    if img != '.DS_Store':\n",
    "        img_ls.append(os.path.join(TEST_DIR, img))\n",
    "test_df  = pd.DataFrame({'img': img_ls}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>../data/original/Type_3/5752.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>../data/original/Type_3/4534.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>../data/original/Type_3/4780.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   img   class\n",
       "6725  ../data/original/Type_3/5752.jpg  Type_3\n",
       "6726  ../data/original/Type_3/4534.jpg  Type_3\n",
       "6727  ../data/original/Type_3/4780.jpg  Type_3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "valid_set[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5332, 2)\n",
      "(1028, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[~train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "train_x = np.zeros((train_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "train_y = np.zeros((train_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in train_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    train_x[i] = x\n",
    "    train_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index in batch_df.index.levels[1].values:\n",
    "            batch_x[i] = train_x[index] \n",
    "            batch_y[i,train_y[index].argmax()] = 1\n",
    "            i += 1\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)\n",
    "        #return (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation... \n",
      "Fine tune part 1\n",
      "Epoch 1/5\n",
      "10144/10144 [==============================] - 171s - loss: 0.7308 - acc: 0.6451 - val_loss: 0.6349 - val_acc: 0.7247\n",
      "Epoch 2/5\n",
      "10144/10144 [==============================] - 175s - loss: 0.4617 - acc: 0.7849 - val_loss: 0.4613 - val_acc: 0.8230\n",
      "Epoch 3/5\n",
      "10144/10144 [==============================] - 190s - loss: 0.3518 - acc: 0.8518 - val_loss: 0.3757 - val_acc: 0.8638\n",
      "Epoch 4/5\n",
      "10144/10144 [==============================] - 163s - loss: 0.2647 - acc: 0.8893 - val_loss: 0.2611 - val_acc: 0.9280\n",
      "Epoch 5/5\n",
      "10144/10144 [==============================] - 162s - loss: 0.2070 - acc: 0.9047 - val_loss: 0.2073 - val_acc: 0.9494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87e50dac10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Model creation... \"\n",
    "nb_epoch = 5\n",
    "model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Start Fine-tuning\n",
    "print \"Fine tune part 1\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          #callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 2\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.1540 - acc: 0.9394 - val_loss: 0.1654 - val_acc: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88e8799990>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_per_epoch = 32*300\n",
    "for layer in model.layers[38:]:\n",
    "    layer.trainable = True\n",
    "#model.optimizer.lr = 1e-5\n",
    "nb_epoch = 1\n",
    "print \"Fine tune part 2\"\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          #callbacks=[model_checkpoint, early_stopping], # , \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 153s - loss: 0.1257 - acc: 0.9471 - val_loss: 0.1317 - val_acc: 0.9708\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0988 - acc: 0.9499 - val_loss: 0.1001 - val_acc: 0.9815\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0781 - acc: 0.9523 - val_loss: 0.0795 - val_acc: 0.9883\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0592 - acc: 0.9649 - val_loss: 0.0553 - val_acc: 0.9971\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0489 - acc: 0.9700 - val_loss: 0.0445 - val_acc: 0.9971\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0412 - acc: 0.9747 - val_loss: 0.0360 - val_acc: 0.9981\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0346 - acc: 0.9769 - val_loss: 0.0305 - val_acc: 0.9981\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0285 - acc: 0.9831 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0244 - acc: 0.9807 - val_loss: 0.0215 - val_acc: 0.9990\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 152s - loss: 0.0211 - acc: 0.9779 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "test_preds_ls = []\n",
    "for ii in range(10):\n",
    "    test_preds_ls.append(model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) \n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=1,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              #callbacks=[model_checkpoint, early_stopping], # , \n",
    "              )\n",
    "test_preds_ls.append(model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                        val_samples = test_df.shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = sum(test_preds_ls)/len(test_preds_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.jpg</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.999464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504.jpg</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.028620</td>\n",
       "      <td>0.971061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.jpg</td>\n",
       "      <td>0.056964</td>\n",
       "      <td>0.942842</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name    Type_1    Type_2    Type_3\n",
       "0     78.jpg  0.000011  0.000524  0.999464\n",
       "1    504.jpg  0.000319  0.028620  0.971061\n",
       "2     31.jpg  0.056964  0.942842  0.000193"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FileLink' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c3fe6f6f7a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubm_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, compression='gzip')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mFileLink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubm_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FileLink' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_remove_addl_10xbag_cut0.6_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_remove_addl_10xbag_cut0.6_' + timestr + '.csv' #'.csv.gz'\n",
    "    \n",
    "test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
