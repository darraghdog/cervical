{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import gc, math\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "ROWS, COLS = 224, 224\n",
    "#CHECKPOINT_DIR = 'log/checkpoint06/'\n",
    "BATCHSIZE = 32\n",
    "CERV_CLASSES = ['Type_1', 'Type_2', 'Type_3']\n",
    "nb_perClass = int(BATCHSIZE / len(CERV_CLASSES))\n",
    "TRAIN_DIR = '../data/cropped/train'\n",
    "TEST_DIR = '../data/cropped/test'\n",
    "DATA_DIR = '../data'\n",
    "num_class = len(CERV_CLASSES)\n",
    "full = False\n",
    "bags = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "y_ls = []\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(TRAIN_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(TRAIN_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "# for typ in CERV_CLASSES:\n",
    "#     for img in os.listdir(os.path.join(DATA_DIR, typ)):\n",
    "#         if img != '.DS_Store':\n",
    "#             img_ls.append(os.path.join(DATA_DIR, typ, img))\n",
    "#             y_ls.append(typ)\n",
    "train_all  = pd.DataFrame({'class': y_ls, 'img': img_ls, })[['img', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "for img in os.listdir(TEST_DIR):\n",
    "    if img != '.DS_Store':\n",
    "        img_ls.append(os.path.join(TEST_DIR, img))\n",
    "test_df  = pd.DataFrame({'img': img_ls}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>../data/cropped/train/Type_3/4217_T3_additiona...</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>../data/cropped/train/Type_3/4816_T3_additiona...</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>../data/cropped/train/Type_3/4851_T3_additiona...</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    img   class\n",
       "8209  ../data/cropped/train/Type_3/4217_T3_additiona...  Type_3\n",
       "8210  ../data/cropped/train/Type_3/4816_T3_additiona...  Type_3\n",
       "8211  ../data/cropped/train/Type_3/4851_T3_additiona...  Type_3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            #x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "            i += 1\n",
    "        #return (batch_x, batch_y)\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']\n",
      "['Type_2/1315.jpg', 'train/Type_2/162.jpg', 'train/Type_2/270.jpg', 'train/Type_2/382.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "print(valid_set[-4:])\n",
    "print(valid_set[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type_1/5975.jpg', 'Type_1/3526.jpg', 'Type_1/2402.jpg', 'Type_1/4943.jpg', 'Type_1/6414.jpg', 'Type_1/3832.jpg', 'Type_1/5769.jpg', 'Type_1/6182.jpg', 'Type_1/888.jpg', 'Type_1/1189.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Get the same validation set in terms of the new naming for the crops\n",
    "trnidx = []\n",
    "for c, row in train_all.iterrows():\n",
    "    typ = row['img'].split('/')[-2]\n",
    "    additional = True if 'additional' in row['img'] else False\n",
    "    img = row['img'].split('/')[-1].split('_')[0]\n",
    "    if additional:\n",
    "        trnidx.append(typ+'/'+img+'.jpg')\n",
    "    else:\n",
    "        trnidx.append('train/'+typ+'/'+img+'.jpg')\n",
    "print trnidx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6570, 2)\n",
      "(1642, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[[f in valid_set for f in trnidx]]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[[f not in valid_set for f in trnidx]]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(df, datagen, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            # typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            # x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%100 == 0: print(batch_index)\n",
    "        # return (batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "model_checkpoint = ModelCheckpoint(filepath=CHECKPOINT_DIR+'weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "# learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "# tensorboard = TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=False, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation... \n",
      "Fine tune part 1\n",
      "Epoch 1/2\n",
      "11104/11136 [============================>.] - ETA: 1s - loss: 0.9367 - acc: 0.5362Epoch 00000: val_loss improved from inf to 1.07257, saving model to log/checkpoint06/weights.000-1.0726.hdf5\n",
      "11136/11136 [==============================] - 688s - loss: 0.9366 - acc: 0.5364 - val_loss: 1.0726 - val_acc: 0.4677\n",
      "Epoch 2/2\n",
      "11104/11136 [============================>.] - ETA: 1s - loss: 0.7480 - acc: 0.6785Epoch 00001: val_loss improved from 1.07257 to 0.98491, saving model to log/checkpoint06/weights.001-0.9849.hdf5\n",
      "11136/11136 [==============================] - 691s - loss: 0.7477 - acc: 0.6784 - val_loss: 0.9849 - val_acc: 0.5116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4152a2c90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Model creation... \"\n",
    "nb_epoch = 2\n",
    "model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "model.optimizer.lr = 1e-5\n",
    "# Start Fine-tuning\n",
    "print \"Fine tune part 1\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          #callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Resnet50\n",
    "# fine tuning\n",
    "# 164 conv5c+top\n",
    "# 142 conv5+top\n",
    "# 80 conv4+conv5+top\n",
    "# 38 conv3+conv4+conv5+top\n",
    "start_layer = 164\n",
    "\n",
    "for layer in model.layers[start_layer:]:\n",
    "    layer.trainable = True\n",
    "model.optimizer.lr = 1e-6\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 2\n",
      "Epoch 1/10\n",
      "11136/11136 [==============================] - 733s - loss: 0.5253 - acc: 0.8144 - val_loss: 0.9483 - val_acc: 0.5378\n",
      "Epoch 2/10\n",
      "11136/11136 [==============================] - 733s - loss: 0.4285 - acc: 0.8676 - val_loss: 0.9462 - val_acc: 0.5591\n",
      "Epoch 3/10\n",
      "11136/11136 [==============================] - 737s - loss: 0.3438 - acc: 0.9101 - val_loss: 0.9488 - val_acc: 0.5761\n",
      "Epoch 4/10\n",
      "  192/11136 [..............................] - ETA: 688s - loss: 0.2812 - acc: 0.9531"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4648dce0693d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m           \u001b[0;31m#callbacks=[model_checkpoint, early_stopping], # ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           )\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print \"Fine tune part 2\"\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          #callbacks=[model_checkpoint, early_stopping], # , \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 3\n",
      "Epoch 1/10\n",
      "11136/11136 [==============================] - 742s - loss: 0.2738 - acc: 0.9353 - val_loss: 0.9818 - val_acc: 0.5627\n",
      "Epoch 2/10\n",
      "11136/11136 [==============================] - 741s - loss: 0.2192 - acc: 0.9513 - val_loss: 0.9930 - val_acc: 0.5847\n",
      "Epoch 3/10\n",
      "11136/11136 [==============================] - 714s - loss: 0.1709 - acc: 0.9682 - val_loss: 1.0209 - val_acc: 0.5901\n",
      "Epoch 4/10\n",
      "11136/11136 [==============================] - 690s - loss: 0.1338 - acc: 0.9758 - val_loss: 1.0413 - val_acc: 0.6005\n",
      "Epoch 5/10\n",
      "11136/11136 [==============================] - 690s - loss: 0.1066 - acc: 0.9770 - val_loss: 1.0537 - val_acc: 0.5999\n",
      "Epoch 6/10\n",
      "11136/11136 [==============================] - 689s - loss: 0.0835 - acc: 0.9704 - val_loss: 1.0994 - val_acc: 0.5895\n",
      "Epoch 7/10\n",
      "11136/11136 [==============================] - 688s - loss: 0.0672 - acc: 0.9804 - val_loss: 1.1133 - val_acc: 0.6023\n",
      "Epoch 8/10\n",
      "11136/11136 [==============================] - 691s - loss: 0.0544 - acc: 0.9751 - val_loss: 1.1468 - val_acc: 0.6017\n",
      "Epoch 9/10\n",
      "11136/11136 [==============================] - 690s - loss: 0.0428 - acc: 0.9705 - val_loss: 1.1860 - val_acc: 0.6127\n",
      "Epoch 10/10\n",
      "11136/11136 [==============================] - 687s - loss: 0.0331 - acc: 0.9771 - val_loss: 1.1944 - val_acc: 0.6072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe40aaa6a90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine tuning\n",
    "# 164 conv5c+top\n",
    "# 142 conv5+top\n",
    "# 80 conv4+conv5+top\n",
    "# 38 conv3+conv4+conv5+top\n",
    "start_layer = 142\n",
    "for layer in model.layers[start_layer:]:\n",
    "    layer.trainable = True\n",
    "model.optimizer.lr = 1e-6\n",
    "nb_epoch = 10\n",
    "print \"Fine tune part 3\"\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          #callbacks=[model_checkpoint, early_stopping], # , \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from keras.models import load_model, model_from_json\n",
    "#model = load_model('log/checkpoint01weights.003-0.7728.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hack to solve issue on model loading : https://github.com/fchollet/keras/issues/4044\n",
    "import glob\n",
    "import h5py\n",
    "model_files = sorted(glob.glob(CHECKPOINT_DIR + '*.hdf5'))\n",
    "for model_file in model_files:\n",
    "    print(\"Update '{}'\".format(model_file))\n",
    "    with h5py.File(model_file, 'a') as f:\n",
    "        if 'optimizer_weights' in f.keys():\n",
    "            del f['optimizer_weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a prediction from a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model(CHECKPOINT_DIR + 'weights.009-0.2856.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_resnet_raw_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_resnet_raw_' + timestr + '.csv' #'.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "#test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "#FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag the predictions from a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "# there is apparently overfitting on the later epochs so exclude the epochs where we unfroze the top layers\n",
    "files = [f for f in files if float(f.split('-')[-1][:-5])>0.26]\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "min_id = np.array(val_losses).argsort()[:bags].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop the lowest val losses and get a prediction for each\n",
    "test_preds_ls = []\n",
    "for index in min_id:\n",
    "    print('Loading model from checkpoints file ' + files[index])\n",
    "    test_model = load_model(files[index])\n",
    "    test_model_name = files[index].split('/')[-2][-1:]+'_'+files[index].split('/')[-1]\n",
    "    test_preds_ls.append(test_model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) \n",
    "    del test_model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = sum(test_preds_ls)/len(test_preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "    \n",
    "#test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "#FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
