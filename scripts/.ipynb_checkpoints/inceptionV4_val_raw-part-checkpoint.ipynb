{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "ROWS, COLS = 224, 224\n",
    "CHECKPOINT_DIR = 'log/checkpoint03/'\n",
    "BATCHSIZE = 32\n",
    "CERV_CLASSES = ['Type_1', 'Type_2', 'Type_3']\n",
    "nb_perClass = int(BATCHSIZE / len(CERV_CLASSES))\n",
    "TRAIN_DIR = '../data/train'\n",
    "TEST_DIR = '../data/test'\n",
    "DATA_DIR = '../data'\n",
    "num_class = len(CERV_CLASSES)\n",
    "full = False\n",
    "bags = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "y_ls = []\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(TRAIN_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(TRAIN_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(DATA_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(DATA_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "train_all  = pd.DataFrame({'class': y_ls, 'img': img_ls, })[['img', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "for img in os.listdir(TEST_DIR):\n",
    "    if img != '.DS_Store':\n",
    "        img_ls.append(os.path.join(TEST_DIR, img))\n",
    "test_df  = pd.DataFrame({'img': img_ls}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8209</th>\n",
       "      <td>../data/Type_3/5391.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8210</th>\n",
       "      <td>../data/Type_3/4116.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>../data/Type_3/568.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          img   class\n",
       "8209  ../data/Type_3/5391.jpg  Type_3\n",
       "8210  ../data/Type_3/4116.jpg  Type_3\n",
       "8211   ../data/Type_3/568.jpg  Type_3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            #x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "            i += 1\n",
    "        #return (batch_x, batch_y)\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "valid_set[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6570, 2)\n",
      "(1642, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[train_all['img'].str.replace('../data/', '').isin(valid_set)]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[~train_all['img'].str.replace('../data/', '').isin(valid_set)]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#samples_per_epoch = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(df, datagen, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            # typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            # x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%100 == 0: print(batch_index)\n",
    "        # return (batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')        \n",
    "model_checkpoint = ModelCheckpoint(filepath=CHECKPOINT_DIR+'weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "# learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "# tensorboard = TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=False, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation... \n",
      "Fine tune part 1\n",
      "Epoch 1/2\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.9250 - acc: 0.4975 Epoch 00000: val_loss improved from inf to 1.06672, saving model to log/checkpoint03/weights.000-1.0667.hdf5\n",
      "11136/11136 [==============================] - 2245s - loss: 0.9246 - acc: 0.4979 - val_loss: 1.0667 - val_acc: 0.4580\n",
      "Epoch 2/2\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.7221 - acc: 0.6560 Epoch 00001: val_loss improved from 1.06672 to 1.00949, saving model to log/checkpoint03/weights.001-1.0095.hdf5\n",
      "11136/11136 [==============================] - 2189s - loss: 0.7226 - acc: 0.6560 - val_loss: 1.0095 - val_acc: 0.4903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01c4da4290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Model creation... \"\n",
    "nb_epoch = 2\n",
    "model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Start Fine-tuning\n",
    "print \"Fine tune part 1\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 1A\n",
      "Epoch 1/4\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.5887 - acc: 0.7478 Epoch 00000: val_loss improved from 1.00949 to 0.96136, saving model to log/checkpoint03/weights.000-0.9614.hdf5\n",
      "11136/11136 [==============================] - 2221s - loss: 0.5888 - acc: 0.7478 - val_loss: 0.9614 - val_acc: 0.5250\n",
      "Epoch 2/4\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.4866 - acc: 0.8093 Epoch 00001: val_loss did not improve\n",
      "11136/11136 [==============================] - 2193s - loss: 0.4863 - acc: 0.8095 - val_loss: 0.9617 - val_acc: 0.5463\n",
      "Epoch 3/4\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.3972 - acc: 0.8474 Epoch 00002: val_loss improved from 0.96136 to 0.94397, saving model to log/checkpoint03/weights.002-0.9440.hdf5\n",
      "11136/11136 [==============================] - 2204s - loss: 0.3968 - acc: 0.8476 - val_loss: 0.9440 - val_acc: 0.5579\n",
      "Epoch 4/4\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.3218 - acc: 0.8742 Epoch 00003: val_loss did not improve\n",
      "11136/11136 [==============================] - 2195s - loss: 0.3216 - acc: 0.8742 - val_loss: 0.9676 - val_acc: 0.5615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01c4da44d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Fine-tuning\n",
    "nb_epoch = 4\n",
    "print \"Fine tune part 1A\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from keras.models import load_model, model_from_json\n",
    "#model = load_model('log/checkpoint01weights.003-0.7728.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 2\n",
      "Epoch 1/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.2575 - acc: 0.9041 Epoch 00000: val_loss did not improve\n",
      "11136/11136 [==============================] - 2191s - loss: 0.2575 - acc: 0.9041 - val_loss: 0.9763 - val_acc: 0.5798\n",
      "Epoch 2/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.2003 - acc: 0.9244 Epoch 00001: val_loss did not improve\n",
      "11136/11136 [==============================] - 2162s - loss: 0.2001 - acc: 0.9245 - val_loss: 0.9937 - val_acc: 0.5974\n",
      "Epoch 3/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.1639 - acc: 0.9439 Epoch 00002: val_loss did not improve\n",
      "11136/11136 [==============================] - 2157s - loss: 0.1639 - acc: 0.9439 - val_loss: 1.0188 - val_acc: 0.5968\n",
      "Epoch 4/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.1270 - acc: 0.9561 Epoch 00003: val_loss did not improve\n",
      "11136/11136 [==============================] - 2167s - loss: 0.1269 - acc: 0.9560 - val_loss: 1.0343 - val_acc: 0.5981\n",
      "Epoch 5/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.0982 - acc: 0.9619 Epoch 00004: val_loss did not improve\n",
      "11136/11136 [==============================] - 2156s - loss: 0.0981 - acc: 0.9620 - val_loss: 1.0654 - val_acc: 0.6035\n",
      "Epoch 6/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.0808 - acc: 0.9689 Epoch 00005: val_loss did not improve\n",
      "11136/11136 [==============================] - 2153s - loss: 0.0808 - acc: 0.9689 - val_loss: 1.0870 - val_acc: 0.6054\n",
      "Epoch 7/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.0632 - acc: 0.9735 Epoch 00006: val_loss did not improve\n",
      "11136/11136 [==============================] - 2195s - loss: 0.0632 - acc: 0.9736 - val_loss: 1.1064 - val_acc: 0.6102\n",
      "Epoch 8/10\n",
      "11104/11136 [============================>.] - ETA: 6s - loss: 0.0506 - acc: 0.9742 Epoch 00007: val_loss did not improve\n",
      "11136/11136 [==============================] - 2150s - loss: 0.0506 - acc: 0.9742 - val_loss: 1.1452 - val_acc: 0.6078\n",
      "Epoch 9/10\n",
      "10816/11136 [============================>.] - ETA: 61s - loss: 0.0397 - acc: 0.9769"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-acad9d024dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m           )\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1524\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m                             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for layer in model.layers[38:]:\n",
    "    layer.trainable = True\n",
    "#model.optimizer.lr = 1e-5\n",
    "nb_epoch = 10\n",
    "print \"Fine tune part 2\"\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          callbacks=[model_checkpoint, early_stopping], # , \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  512/11136 [>.............................] - ETA: 2120s - loss: 0.0346 - acc: 0.9707"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stopping, model_checkpoint],\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "# val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "# # weights.009-0.2856.hdf5\n",
    "# index = val_losses.index(min(val_losses))\n",
    "# print('Loading model from checkpoints file ' + files[index])\n",
    "# model = load_model(files[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hack to solve issue on model loading : https://github.com/fchollet/keras/issues/4044\n",
    "import glob\n",
    "import h5py\n",
    "model_files = sorted(glob.glob(CHECKPOINT_DIR + '*.hdf5'))\n",
    "for model_file in model_files:\n",
    "    print(\"Update '{}'\".format(model_file))\n",
    "    with h5py.File(model_file, 'a') as f:\n",
    "        if 'optimizer_weights' in f.keys():\n",
    "            del f['optimizer_weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a prediction from a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model(CHECKPOINT_DIR + 'weights.009-0.2856.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_resnet_raw_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_resnet_raw_' + timestr + '.csv' #'.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "#test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "#FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag the predictions from a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(CHECKPOINT_DIR+'*')\n",
    "# there is apparently overfitting on the later epochs so exclude the epochs where we unfroze the top layers\n",
    "files = [f for f in files if float(f.split('-')[-1][:-5])>0.26]\n",
    "val_losses = [float(f.split('-')[-1][:-5]) for f in files]\n",
    "min_id = np.array(val_losses).argsort()[:bags].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop the lowest val losses and get a prediction for each\n",
    "test_preds_ls = []\n",
    "for index in min_id:\n",
    "    print('Loading model from checkpoints file ' + files[index])\n",
    "    test_model = load_model(files[index])\n",
    "    test_model_name = files[index].split('/')[-2][-1:]+'_'+files[index].split('/')[-1]\n",
    "    test_preds_ls.append(test_model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) \n",
    "    del test_model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = sum(test_preds_ls)/len(test_preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_resnet_raw_5xbag_' + timestr + '.csv' #'.csv.gz'\n",
    "    \n",
    "#test_sub.to_csv(subm_name, index=False)#, compression='gzip')\n",
    "#FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
