{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 85.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "ROWS, COLS = 224, 224\n",
    "CHECKPOINT_DIR = 'log/checkpoint09/'\n",
    "BATCHSIZE = 32\n",
    "CERV_CLASSES = ['Type_1', 'Type_2', 'Type_3']\n",
    "nb_perClass = int(BATCHSIZE / len(CERV_CLASSES))\n",
    "TRAIN_DIR = '../data/gmm/train'\n",
    "TEST_DIR = '../data/gmm/test'\n",
    "DATA_DIR = '../data/gmm'\n",
    "num_class = len(CERV_CLASSES)\n",
    "full = True\n",
    "bags = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            #x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "            i += 1\n",
    "        #return (batch_x, batch_y)\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(df, datagen, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = row[0]\n",
    "            # typ_class = row[1]\n",
    "            img = Image.open(image_file).resize((ROWS, COLS))\n",
    "            img = img.convert('RGB')\n",
    "            x = np.asarray(img, dtype=K.floatx())\n",
    "            # x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%100 == 0: print(batch_index)\n",
    "        # return (batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480, 2)\n",
      "(6726, 2)\n"
     ]
    }
   ],
   "source": [
    "img_ls = []\n",
    "y_ls = []\n",
    "imgadd_ls = []\n",
    "yadd_ls = []\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(TRAIN_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            img_ls.append(os.path.join(TRAIN_DIR, typ, img))\n",
    "            y_ls.append(typ)\n",
    "for typ in CERV_CLASSES:\n",
    "    for img in os.listdir(os.path.join(DATA_DIR, typ)):\n",
    "        if img != '.DS_Store':\n",
    "            imgadd_ls.append(os.path.join(DATA_DIR, typ, img))\n",
    "            yadd_ls.append(typ)\n",
    "train_orig_all  = pd.DataFrame({'class': y_ls, 'img': img_ls, })[['img', 'class']]\n",
    "train_addl_all  = pd.DataFrame({'class': yadd_ls, 'img': imgadd_ls, })[['img', 'class']]\n",
    "print(train_orig_all.shape)\n",
    "print(train_addl_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = train_orig_all\n",
    "test_df =   train_addl_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "valid_set[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480, 2)\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[~train_all['img'].str.replace('../data/original/', '').isin(valid_set)]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/original/Type_1/6461.jpg</td>\n",
       "      <td>0.704089</td>\n",
       "      <td>0.080506</td>\n",
       "      <td>0.215405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/original/Type_1/1081.jpg</td>\n",
       "      <td>0.055063</td>\n",
       "      <td>0.780277</td>\n",
       "      <td>0.164660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/original/Type_1/6333.jpg</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.349753</td>\n",
       "      <td>0.518872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image_name    Type_1    Type_2    Type_3\n",
       "0  ../data/original/Type_1/6461.jpg  0.704089  0.080506  0.215405\n",
       "1  ../data/original/Type_1/1081.jpg  0.055063  0.780277  0.164660\n",
       "2  ../data/original/Type_1/6333.jpg  0.131375  0.349753  0.518872"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = pd.read_csv('../feat/additional_pred.csv')\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_additional = []\n",
    "bad_additional = []\n",
    "for c, row in test_sub.iterrows():\n",
    "    typ = int(row[0].split('/')[3][-1])\n",
    "    if row[typ] >= 0.2:\n",
    "        good_additional.append(row[0].replace('/original', '/gmm'))\n",
    "    else:\n",
    "        bad_additional.append(row[0].replace('/original', '/gmm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5252, 1477)\n"
     ]
    }
   ],
   "source": [
    "print(len(good_additional), len(bad_additional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have the good and bad additionals, lets do a full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = pd.concat([train_orig_all, train_addl_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = train_all[~train_all['img'].isin(bad_additional)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ls = []\n",
    "for img in os.listdir(TEST_DIR):\n",
    "    if img != '.DS_Store':\n",
    "        img_ls.append(os.path.join(TEST_DIR, img))\n",
    "test_df  = pd.DataFrame({'img': img_ls}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>../data/gmm/Type_3/4534.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>../data/gmm/Type_3/4780.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>../data/gmm/Type_3/4696.jpg</td>\n",
       "      <td>Type_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              img   class\n",
       "6723  ../data/gmm/Type_3/4534.jpg  Type_3\n",
       "6724  ../data/gmm/Type_3/4780.jpg  Type_3\n",
       "6725  ../data/gmm/Type_3/4696.jpg  Type_3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type_2/3498.jpg', 'Type_2/1341.jpg', 'Type_3/6017.jpg', 'Type_2/5629.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and valid\n",
    "valid_set = pd.read_csv(\"../val_images.csv\", header = None, names = ['img']).img.tolist()\n",
    "valid_set[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6732, 2)\n",
      "(1344, 2)\n"
     ]
    }
   ],
   "source": [
    "valid_df = train_all[train_all['img'].str.replace('../data/gmm/', '').isin(valid_set)]\n",
    "if full == True:\n",
    "    train_df = train_all\n",
    "else:\n",
    "    train_df = train_all[~train_all['img'].str.replace('../data/gmm/', '').isin(valid_set)]\n",
    "samples_per_epoch=BATCHSIZE*math.ceil(train_df.groupby('class').size()['Type_2']/nb_perClass)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make our validation set\n",
    "l = valid_df.groupby('class').size()\n",
    "train_x = np.zeros((train_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "train_y = np.zeros((train_df.shape[0], len(CERV_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in train_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = row[0]\n",
    "    typ_class = row[1]\n",
    "    img = Image.open(image_file).resize((ROWS, COLS))\n",
    "    img = img.convert('RGB')\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    # x = datagen.random_transform(x)\n",
    "    x = preprocess_input(x)\n",
    "    train_x[i] = x\n",
    "    train_y[i,CERV_CLASSES.index(typ_class)] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(CERV_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby('class', as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index in batch_df.index.levels[1].values:\n",
    "            batch_x[i] = train_x[index] \n",
    "            batch_y[i,train_y[index].argmax()] = 1\n",
    "            i += 1\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)\n",
    "        #return (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation... \n",
      "Fine tune part 1\n",
      "Epoch 1/5\n",
      "12512/12512 [==============================] - 351s - loss: 0.8314 - acc: 0.5448 - val_loss: 0.7744 - val_acc: 0.6451\n",
      "Epoch 2/5\n",
      "12512/12512 [==============================] - 209s - loss: 0.5786 - acc: 0.7022 - val_loss: 0.6064 - val_acc: 0.7388\n",
      "Epoch 3/5\n",
      "12512/12512 [==============================] - 213s - loss: 0.4655 - acc: 0.7697 - val_loss: 0.4726 - val_acc: 0.8222\n",
      "Epoch 4/5\n",
      "12512/12512 [==============================] - 220s - loss: 0.3600 - acc: 0.8191 - val_loss: 0.3760 - val_acc: 0.8772\n",
      "Epoch 5/5\n",
      "12512/12512 [==============================] - 218s - loss: 0.2967 - acc: 0.8458 - val_loss: 0.3224 - val_acc: 0.9003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f14ce4ff6d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Model creation... \"\n",
    "nb_epoch = 5\n",
    "model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Start Fine-tuning\n",
    "print \"Fine tune part 1\"\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          #callbacks=[early_stopping, model_checkpoint],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune part 2\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 174s - loss: 0.2395 - acc: 0.8729 - val_loss: 0.2636 - val_acc: 0.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16292c8dd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_per_epoch = 32*300\n",
    "for layer in model.layers[38:]:\n",
    "    layer.trainable = True\n",
    "#model.optimizer.lr = 1e-5\n",
    "nb_epoch = 1\n",
    "print \"Fine tune part 2\"\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          #callbacks=[model_checkpoint, early_stopping], # , \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 175s - loss: 0.1926 - acc: 0.8918 - val_loss: 0.2320 - val_acc: 0.9353\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 179s - loss: 0.1658 - acc: 0.9008 - val_loss: 0.1914 - val_acc: 0.9494\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 178s - loss: 0.1360 - acc: 0.9111 - val_loss: 0.1622 - val_acc: 0.9635\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 177s - loss: 0.1139 - acc: 0.9172 - val_loss: 0.1195 - val_acc: 0.9762\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 175s - loss: 0.0995 - acc: 0.9222 - val_loss: 0.1184 - val_acc: 0.9725\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 194s - loss: 0.0804 - acc: 0.9258 - val_loss: 0.0909 - val_acc: 0.9821\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 223s - loss: 0.0689 - acc: 0.9302 - val_loss: 0.0751 - val_acc: 0.9881\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 213s - loss: 0.0560 - acc: 0.9324 - val_loss: 0.0589 - val_acc: 0.9926\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 158s - loss: 0.0503 - acc: 0.9330 - val_loss: 0.0517 - val_acc: 0.9933\n",
      "0\n",
      "Epoch 1/1\n",
      "9600/9600 [==============================] - 158s - loss: 0.0421 - acc: 0.9348 - val_loss: 0.0417 - val_acc: 0.9978\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "test_preds_ls = []\n",
    "for ii in range(10):\n",
    "    test_preds_ls.append(model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                         val_samples = test_df.shape[0])) \n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=1,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              #callbacks=[model_checkpoint, early_stopping], # , \n",
    "              )\n",
    "test_preds_ls.append(model.predict_generator(test_generator(test_df, train_datagen), \n",
    "                                        val_samples = test_df.shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = sum(test_preds_ls)/len(test_preds_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>Type_1</th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.jpg</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.996385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504.jpg</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>0.184447</td>\n",
       "      <td>0.782622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.jpg</td>\n",
       "      <td>0.413796</td>\n",
       "      <td>0.558904</td>\n",
       "      <td>0.027299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name    Type_1    Type_2    Type_3\n",
       "0     78.jpg  0.000111  0.003504  0.996385\n",
       "1    504.jpg  0.032931  0.184447  0.782622\n",
       "2     31.jpg  0.413796  0.558904  0.027299"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = pd.DataFrame(test_preds, columns=CERV_CLASSES)\n",
    "test_sub['image_name'] = test_df['img'].str.split('/').apply(lambda x: x[-1])\n",
    "test_sub = test_sub[['image_name'] + CERV_CLASSES ]\n",
    "test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "if full:\n",
    "    subm_name = '../sub/sub_dara_full_gmm_remove_addl_10xbag.csv' #'.csv.gz'\n",
    "else:\n",
    "    subm_name = '../sub/sub_dara_part_gmm_remove_addl_10xbag.csv' #'.csv.gz'\n",
    "    \n",
    "test_sub.to_csv(subm_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
